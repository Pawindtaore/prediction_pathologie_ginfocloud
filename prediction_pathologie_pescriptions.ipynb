{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer,RobustScaler,MinMaxScaler,StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score,validation_curve,GridSearchCV,learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charger_fichier(path):\n",
    "    ext = path.split(\".\")[-1]\n",
    "    if ext in ['csv','txt']:\n",
    "        data = pd.read_csv(path)\n",
    "    elif ext in ['xls','xlsx']:\n",
    "        data = pd.read_excel(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation(df, method):\n",
    "    \"\"\"\n",
    "    Méthode permettant de normaliser les données quantitatives d'un dataframe\n",
    "    @params df : Dataframe\n",
    "    @params method: Entier compris entre 1 et 3\n",
    "        1 => Utilisation de MinMax\n",
    "        2 => Utilisation de Z-score\n",
    "        3 => Utilisation de la méthode robuste (résiste aux valeurs aberrantes)\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()  # Utiliser une copie du DataFrame pour éviter de modifier l'original\n",
    "    \n",
    "    if method == 1:\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 2:\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = RobustScaler()\n",
    "    \n",
    "    scaled_data = scaler.fit_transform(df_copy.select_dtypes(include=['int', 'float']))\n",
    "    df_copy.loc[:, df_copy.select_dtypes(include=['int', 'float']).columns] = scaled_data\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = charger_fichier('donnees_generer_complet_consultations_medicales.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004 entries, 0 to 1003\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Age (en mois)         1004 non-null   float64\n",
      " 1   Sexe                  1004 non-null   object \n",
      " 2   Poids (kg)            1004 non-null   float64\n",
      " 3   Symptômes             1004 non-null   object \n",
      " 4   Antécédents medicaux  1004 non-null   object \n",
      " 5   Pathologie            1004 non-null   object \n",
      " 6   Traitement            1004 non-null   object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 55.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (en mois)</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>Poids (kg)</th>\n",
       "      <th>Symptômes</th>\n",
       "      <th>Antécédents medicaux</th>\n",
       "      <th>Pathologie</th>\n",
       "      <th>Traitement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420.0</td>\n",
       "      <td>M</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Tremblements, Sueurs, Anxiété</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "      <td>Donner 15 à 20 g de sucre sous forme de morcea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504.0</td>\n",
       "      <td>F</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Confusion, Convulsions</td>\n",
       "      <td>Diabète de type 2</td>\n",
       "      <td>Hypoglycémie sévère</td>\n",
       "      <td>Administrer 1 ml/ de glucose 50% en IV lente (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600.0</td>\n",
       "      <td>M</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Tremblements, Pâleur</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "      <td>Donner 15 à 20 g de sucre sous forme de morcea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>336.0</td>\n",
       "      <td>F</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fatigue, Léthargie</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "      <td>Donner 15 à 20 g de sucre sous forme de morcea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540.0</td>\n",
       "      <td>M</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Confusion, Coma</td>\n",
       "      <td>Diabète de type 1</td>\n",
       "      <td>Hypoglycémie sévère</td>\n",
       "      <td>Administrer 1 ml/ de glucose à 50% en IV lente...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age (en mois) Sexe  Poids (kg)                      Symptômes  \\\n",
       "0          420.0    M        80.0  Tremblements, Sueurs, Anxiété   \n",
       "1          504.0    F        68.0         Confusion, Convulsions   \n",
       "2          600.0    M        95.0           Tremblements, Pâleur   \n",
       "3          336.0    F        60.0             Fatigue, Léthargie   \n",
       "4          540.0    M        92.0                Confusion, Coma   \n",
       "\n",
       "  Antécédents medicaux           Pathologie  \\\n",
       "0                Aucun         Hypoglycémie   \n",
       "1    Diabète de type 2  Hypoglycémie sévère   \n",
       "2                Aucun         Hypoglycémie   \n",
       "3                Aucun         Hypoglycémie   \n",
       "4    Diabète de type 1  Hypoglycémie sévère   \n",
       "\n",
       "                                          Traitement  \n",
       "0  Donner 15 à 20 g de sucre sous forme de morcea...  \n",
       "1  Administrer 1 ml/ de glucose 50% en IV lente (...  \n",
       "2  Donner 15 à 20 g de sucre sous forme de morcea...  \n",
       "3  Donner 15 à 20 g de sucre sous forme de morcea...  \n",
       "4  Administrer 1 ml/ de glucose à 50% en IV lente...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (en mois)</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>Poids (kg)</th>\n",
       "      <th>Symptômes</th>\n",
       "      <th>Antécédents medicaux</th>\n",
       "      <th>Pathologie</th>\n",
       "      <th>Traitement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1004.000000</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004.000000</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258</td>\n",
       "      <td>23</td>\n",
       "      <td>61</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plaques cutanées, diarrhée, démence</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Paludisme</td>\n",
       "      <td>prescrire une association de 4 antituberculeux...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>933</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>307.189442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.138546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>225.148615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.560345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>324.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>468.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>960.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age (en mois)  Sexe   Poids (kg)                            Symptômes  \\\n",
       "count     1004.000000  1004  1004.000000                                 1004   \n",
       "unique            NaN     2          NaN                                  258   \n",
       "top               NaN     F          NaN  Plaques cutanées, diarrhée, démence   \n",
       "freq              NaN   510          NaN                                   40   \n",
       "mean       307.189442   NaN    48.138546                                  NaN   \n",
       "std        225.148615   NaN    25.560345                                  NaN   \n",
       "min          2.000000   NaN     3.500000                                  NaN   \n",
       "25%         84.000000   NaN    22.000000                                  NaN   \n",
       "50%        324.000000   NaN    56.000000                                  NaN   \n",
       "75%        468.000000   NaN    70.000000                                  NaN   \n",
       "max        960.000000   NaN    96.000000                                  NaN   \n",
       "\n",
       "       Antécédents medicaux Pathologie  \\\n",
       "count                  1004       1004   \n",
       "unique                   23         61   \n",
       "top                   Aucun  Paludisme   \n",
       "freq                    933         70   \n",
       "mean                    NaN        NaN   \n",
       "std                     NaN        NaN   \n",
       "min                     NaN        NaN   \n",
       "25%                     NaN        NaN   \n",
       "50%                     NaN        NaN   \n",
       "75%                     NaN        NaN   \n",
       "max                     NaN        NaN   \n",
       "\n",
       "                                               Traitement  \n",
       "count                                                1004  \n",
       "unique                                                162  \n",
       "top     prescrire une association de 4 antituberculeux...  \n",
       "freq                                                   40  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age (en mois)           0\n",
       "Sexe                    0\n",
       "Poids (kg)              0\n",
       "Symptômes               0\n",
       "Antécédents medicaux    0\n",
       "Pathologie              0\n",
       "Traitement              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation de la colonne Symptomes en 05 autres colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptomes = df['Symptômes']\n",
    "\n",
    "# Diviser les symptômes en colonnes individuelles\n",
    "for i, symptome in enumerate(symptomes):\n",
    "    if isinstance(symptome, str):  # Vérifier si la valeur est une chaîne de caractères\n",
    "        tabs = symptome.split(',')\n",
    "        for j, tab in enumerate(tabs[:5]):\n",
    "            df.at[i, f'Symptome_{j + 1}'] = tab.strip()\n",
    "\n",
    "# Supprimer la colonne \"Symptômes\" originale\n",
    "df = df.drop(columns=['Symptômes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionnez les 5 dernières colonnes\n",
    "dernieres_colonnes = df.iloc[:, -5:]\n",
    "\n",
    "# Supprimez les 5 dernières colonnes du DataFrame original\n",
    "df = df.iloc[:, :-5]\n",
    "\n",
    "# Insérez les 5 dernières colonnes à la 3e position\n",
    "position_inserer = 3  # L'index 2 correspond à la 3e position (index de base 0)\n",
    "for col in dernieres_colonnes.columns:\n",
    "    df.insert(position_inserer, col, dernieres_colonnes[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hypoglycémie', 'Hypoglycémie sévère', 'Grippe', 'Myalgie',\n",
       "       'Bronchite', 'Dermatite', 'Gastroentérite',\n",
       "       'Angine streptococcique', 'Pyélonéphrite', 'Migraine',\n",
       "       'Ulcère gastrique', 'Infection urinaire', 'Bronchite chronique',\n",
       "       'Otite externe', 'Arthrite rhumatoïde', 'Colite',\n",
       "       'Reflux gastro-œsophagien', 'Colique abdominale', 'Anémie',\n",
       "       'Amaigrissement', 'Obstruction Sévère', 'Obstruction Légère',\n",
       "       'Obstruction Complète Imminente', 'Obstruction Modérée',\n",
       "       'Rhinopharyngite', 'Rhinite', 'Sinusite bactérienne',\n",
       "       'Sinusite virale', 'Angine érythémateuse (virale)',\n",
       "       'Angine bactérienne', 'Angine vésiculeuse (virale)',\n",
       "       'Angine ulcéro-nécrotique (bactérienne)',\n",
       "       'Angine pseudo-membraneuse (bactérienne)',\n",
       "       'Angine érythémateuse (bactérienne)', 'Angine virale',\n",
       "       'Angine ulcéro-nécrotique (virale)', 'Bronchite aiguë',\n",
       "       'Trachéite bactérienne', 'Otite externe aiguë',\n",
       "       'Otite moyenne aiguë (OMA)',\n",
       "       'Otite moyenne chronique suppurée (OMCS)',\n",
       "       'Tuberculose pulmonaire', 'Herpès buccal', 'Herpès labial',\n",
       "       'Stomatite du scorbut', 'Paludisme', 'Onchocercose', 'Rougeole',\n",
       "       'Poliomyélite', 'Anxiété', 'Pellagre', 'Cystite aiguë',\n",
       "       ' prostatite aiguë', 'Trichomonase', 'Insomnie',\n",
       "       'Dermatite séborrhéique', 'Eczéma aigu', 'Eczéma chronique',\n",
       "       'Furoncle', 'Anthrax', 'reflux gastro-œsophagien'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modalités de la variable cible\n",
    "df.loc[:, 'Pathologie'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppresion des colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (en mois)</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>Poids (kg)</th>\n",
       "      <th>Symptome_5</th>\n",
       "      <th>Symptome_4</th>\n",
       "      <th>Symptome_3</th>\n",
       "      <th>Symptome_2</th>\n",
       "      <th>Symptome_1</th>\n",
       "      <th>Antécédents medicaux</th>\n",
       "      <th>Pathologie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420.0</td>\n",
       "      <td>M</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiété</td>\n",
       "      <td>Sueurs</td>\n",
       "      <td>Tremblements</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504.0</td>\n",
       "      <td>F</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Convulsions</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>Diabète de type 2</td>\n",
       "      <td>Hypoglycémie sévère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600.0</td>\n",
       "      <td>M</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pâleur</td>\n",
       "      <td>Tremblements</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>336.0</td>\n",
       "      <td>F</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Léthargie</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540.0</td>\n",
       "      <td>M</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coma</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>Diabète de type 1</td>\n",
       "      <td>Hypoglycémie sévère</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age (en mois) Sexe  Poids (kg) Symptome_5 Symptome_4 Symptome_3  \\\n",
       "0          420.0    M        80.0        NaN        NaN    Anxiété   \n",
       "1          504.0    F        68.0        NaN        NaN        NaN   \n",
       "2          600.0    M        95.0        NaN        NaN        NaN   \n",
       "3          336.0    F        60.0        NaN        NaN        NaN   \n",
       "4          540.0    M        92.0        NaN        NaN        NaN   \n",
       "\n",
       "    Symptome_2    Symptome_1 Antécédents medicaux           Pathologie  \n",
       "0       Sueurs  Tremblements                Aucun         Hypoglycémie  \n",
       "1  Convulsions     Confusion    Diabète de type 2  Hypoglycémie sévère  \n",
       "2       Pâleur  Tremblements                Aucun         Hypoglycémie  \n",
       "3    Léthargie       Fatigue                Aucun         Hypoglycémie  \n",
       "4         Coma     Confusion    Diabète de type 1  Hypoglycémie sévère  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_cols = ['Traitement']\n",
    "df.drop(useless_cols,axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehension des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ = df.select_dtypes(include=['object']).columns\n",
    "for var in cols_:\n",
    "    df[var].value_counts().plot(kind='pie',autopct='%1.1f%%')\n",
    "    plt.title(var)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (en mois)</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>Poids (kg)</th>\n",
       "      <th>Symptome_5</th>\n",
       "      <th>Symptome_4</th>\n",
       "      <th>Symptome_3</th>\n",
       "      <th>Symptome_2</th>\n",
       "      <th>Symptome_1</th>\n",
       "      <th>Antécédents medicaux</th>\n",
       "      <th>Pathologie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436326</td>\n",
       "      <td>M</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiété</td>\n",
       "      <td>Sueurs</td>\n",
       "      <td>Tremblements</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524008</td>\n",
       "      <td>F</td>\n",
       "      <td>0.697297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Convulsions</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>Diabète de type 2</td>\n",
       "      <td>Hypoglycémie sévère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624217</td>\n",
       "      <td>M</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pâleur</td>\n",
       "      <td>Tremblements</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348643</td>\n",
       "      <td>F</td>\n",
       "      <td>0.610811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Léthargie</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>Aucun</td>\n",
       "      <td>Hypoglycémie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.561587</td>\n",
       "      <td>M</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coma</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>Diabète de type 1</td>\n",
       "      <td>Hypoglycémie sévère</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age (en mois) Sexe  Poids (kg) Symptome_5 Symptome_4 Symptome_3  \\\n",
       "0       0.436326    M    0.827027        NaN        NaN    Anxiété   \n",
       "1       0.524008    F    0.697297        NaN        NaN        NaN   \n",
       "2       0.624217    M    0.989189        NaN        NaN        NaN   \n",
       "3       0.348643    F    0.610811        NaN        NaN        NaN   \n",
       "4       0.561587    M    0.956757        NaN        NaN        NaN   \n",
       "\n",
       "    Symptome_2    Symptome_1 Antécédents medicaux           Pathologie  \n",
       "0       Sueurs  Tremblements                Aucun         Hypoglycémie  \n",
       "1  Convulsions     Confusion    Diabète de type 2  Hypoglycémie sévère  \n",
       "2       Pâleur  Tremblements                Aucun         Hypoglycémie  \n",
       "3    Léthargie       Fatigue                Aucun         Hypoglycémie  \n",
       "4         Coma     Confusion    Diabète de type 1  Hypoglycémie sévère  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_normalized = normalisation(df, method=1)\n",
    "# Remplacement des colonnes normalisées dans le DataFrame original\n",
    "df = df_normalized\n",
    "\n",
    "# Afficher le DataFrame après normalisation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encodage des variables qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_symptome_5 = LabelBinarizer()\n",
    "encoder_symptome_4 = LabelBinarizer()\n",
    "encoder_symptome_3 = LabelBinarizer()\n",
    "encoder_symptome_2 = LabelBinarizer()\n",
    "encoder_symptome_1 = LabelBinarizer()\n",
    "encoder_sexe = LabelBinarizer()\n",
    "encoder_antecedents_medicaux = LabelBinarizer()\n",
    "encoder_pathologie = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodage(data, columns, cible):\n",
    "    \n",
    "    #Encodage des variables explicatives qualitative avec LabelBinarizer\n",
    "    cat_col = list(_ for _ in columns)\n",
    "    for col in cat_col:\n",
    "        enc_data = None  # Initialisation de enc_data\n",
    "        if col == \"Symptome_5\":\n",
    "            enc_data = encoder_symptome_5.fit_transform(data.loc[:, col].astype(str))\n",
    "        elif col == \"Symptome_4\":\n",
    "            enc_data = encoder_symptome_4.fit_transform(data.loc[:, col].astype(str))\n",
    "        elif col == \"Symptome_3\":\n",
    "            enc_data = encoder_symptome_3.fit_transform(data.loc[:, col].astype(str))\n",
    "        elif col == \"Symptome_2\":\n",
    "            enc_data = encoder_symptome_2.fit_transform(data.loc[:, col].astype(str))\n",
    "        elif col == \"Symptome_1\":\n",
    "            enc_data = encoder_symptome_1.fit_transform(data.loc[:, col].astype(str))\n",
    "        elif col == \"Antécédents medicaux\":\n",
    "            enc_data = encoder_antecedents_medicaux.fit_transform(data.loc[:, col].astype(str))\n",
    "        elif col == \"Sexe\":\n",
    "            enc_data = encoder_sexe.fit_transform(data.loc[:, col].astype(str))\n",
    "\n",
    "        if enc_data is not None:\n",
    "            prev_mod = [f\"{col}_{mod}\" for mod in list(data.loc[:, col].unique())]\n",
    "            if len(prev_mod) == enc_data.shape[1]:\n",
    "                data[prev_mod] = enc_data\n",
    "                data.drop(col, axis=1, inplace=True)\n",
    "            else:\n",
    "                data.drop(col, axis=1, inplace=True)\n",
    "                data[col] = enc_data\n",
    "            \n",
    "    #Encodage de la variable cible avec LabelEncoder\n",
    "    enc_cible = encoder_pathologie.fit_transform(data.loc[:,cible])\n",
    "    data.drop(cible,axis=1,inplace=True)\n",
    "    data[cible] = enc_cible\n",
    "            \n",
    "    return data\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sexe', 'Symptome_5', 'Symptome_4', 'Symptome_3', 'Symptome_2',\n",
       "       'Symptome_1', 'Antécédents medicaux', 'Pathologie'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Liste des variables categorielles a encoder\n",
    "cols_to_encoder = df.select_dtypes(include=['object']).columns\n",
    "cols_to_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[prev_mod] = enc_data\n",
      "/var/folders/rd/408jh18j04b0rjlsj8z_718m0000gn/T/ipykernel_21380/3471138655.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[cible] = enc_cible\n"
     ]
    }
   ],
   "source": [
    "df=encodage(df,cols_to_encoder,'Pathologie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportez les données traitées vers un fichier CSV\n",
    "df.to_csv('donnees_traites.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = charger_fichier('donnees_traites.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 290)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombres de pathologies présentent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepared_data.loc[:, 'Pathologie'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation des donnees en Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prepared_data['Pathologie']\n",
    "X = prepared_data.drop('Pathologie',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(803, 289)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 289)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche du meilleur estimateur avec ses parametres avec GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "175 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 90, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.05603261 0.06226708\n",
      " 0.06226708        nan 0.06226708 0.06226708        nan        nan\n",
      "        nan        nan 0.06226708 0.23288043 0.23288043        nan\n",
      " 0.23412267 0.23288043        nan        nan        nan        nan\n",
      " 0.45832298 0.66506988 0.66506988        nan 0.66506988 0.66506988\n",
      "        nan        nan        nan        nan 0.88546584 0.90533385\n",
      " 0.90533385        nan 0.90533385 0.90533385        nan        nan\n",
      "        nan        nan 0.92524845 0.93893634 0.93893634        nan\n",
      " 0.93893634 0.93893634        nan        nan        nan        nan\n",
      " 0.93149068 0.93895186 0.93895186        nan 0.9401941  0.93895186\n",
      "        nan        nan        nan        nan 0.93148292 0.93024068\n",
      " 0.93024068        nan 0.93397516 0.93148292]\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = parametres_grid = [\n",
    "    ('K-Nearest Neighbors (KNN)', KNeighborsClassifier(), {\n",
    "        \"n_neighbors\": np.arange(1, 20),\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"]\n",
    "    }),\n",
    "\n",
    "    ('Decision Tree', DecisionTreeClassifier(), {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"splitter\": [\"best\", \"random\"],\n",
    "        \"max_depth\": [None, 2, 4, 6, 8, 10],\n",
    "        \"min_samples_split\": np.arange(2, 10, 1),\n",
    "        \"min_samples_leaf\": list(range(1, 10, 1))\n",
    "    }),\n",
    "\n",
    "    ('Random Forest', RandomForestClassifier(), {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"max_depth\": [None, 1, 3, 5, 7, 9]\n",
    "    }),\n",
    "\n",
    "    ('Bagging', BaggingClassifier(), {\n",
    "        \"n_estimators\": [10, 20, 30],\n",
    "        \"max_samples\": np.arange(0.1, 1.1, 0.1),\n",
    "        \"max_features\": np.arange(0.1, 1.1, 0.1)\n",
    "    }),\n",
    "\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=10000, multi_class='multinomial'), {\n",
    "        \"C\": np.logspace(-3, 3, 7),\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "    }),\n",
    "\n",
    "    ('Naive Bayes', MultinomialNB(), { \n",
    "        \"alpha\": [0.1, 0.5, 1.0], \n",
    "        \"fit_prior\": [True, False]  \n",
    "    }),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "model_names = []\n",
    "best_parametre = []\n",
    "score = []\n",
    "bons_model  = []\n",
    "# Boucle pour tester chaque modèle avec GridSearchCV\n",
    "for model_name, model, param_grid in models:\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5,n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_score = grid_search.score(X_test, y_test)\n",
    "    # print(f\"Meilleurs paramètres pour {model_name} :\")\n",
    "    # print(grid_search.best_params_)\n",
    "    # print(\"Score de validation croisée :\", grid_search.best_score_)\n",
    "    # print(\"\\n\")\n",
    "    score.append(grid_score)\n",
    "    model_names.append(model_name)\n",
    "    best_parametre.append(grid_search.best_params_)\n",
    "    bons_model.append(grid_search)\n",
    "    \n",
    "model_search = pd.DataFrame({\"Algorithme\": model_names, \"Meilleur parametres\": best_parametre, \"score\" : score, \"model_al\" : bons_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Meilleur parametres</th>\n",
       "      <th>score</th>\n",
       "      <th>model_al</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors (KNN)</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=KNeighborsClassif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{'alpha': 0.1, 'fit_prior': False}</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=MultinomialNB(), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'max_features': 0.6, 'max_samples': 1.0, 'n_e...</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=BaggingClassifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=DecisionTreeClass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Algorithme  \\\n",
       "4        Logistic Regression   \n",
       "2              Random Forest   \n",
       "0  K-Nearest Neighbors (KNN)   \n",
       "5                Naive Bayes   \n",
       "3                    Bagging   \n",
       "1              Decision Tree   \n",
       "\n",
       "                                 Meilleur parametres     score  \\\n",
       "4     {'C': 100.0, 'penalty': 'l2', 'solver': 'sag'}  0.935323   \n",
       "2  {'criterion': 'gini', 'max_depth': None, 'max_...  0.925373   \n",
       "0  {'metric': 'euclidean', 'n_neighbors': 1, 'wei...  0.920398   \n",
       "5                 {'alpha': 0.1, 'fit_prior': False}  0.915423   \n",
       "3  {'max_features': 0.6, 'max_samples': 1.0, 'n_e...  0.875622   \n",
       "1  {'criterion': 'gini', 'max_depth': None, 'min_...  0.850746   \n",
       "\n",
       "                                            model_al  \n",
       "4  GridSearchCV(cv=5,\\n             estimator=Log...  \n",
       "2  GridSearchCV(cv=5, estimator=RandomForestClass...  \n",
       "0  GridSearchCV(cv=5, estimator=KNeighborsClassif...  \n",
       "5  GridSearchCV(cv=5, estimator=MultinomialNB(), ...  \n",
       "3  GridSearchCV(cv=5, estimator=BaggingClassifier...  \n",
       "1  GridSearchCV(cv=5, estimator=DecisionTreeClass...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=10000,\n",
       "                                          multi_class=&#x27;multinomial&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=10000,\n",
       "                                          multi_class=&#x27;multinomial&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=10000,\n",
       "                                          multi_class='multinomial'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= model_search['model_al'][4]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9353233830845771"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  3,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  7,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 13,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score d'entraitenant :  0.9962640099626401\n",
      "Score de test :  0.9353233830845771\n"
     ]
    }
   ],
   "source": [
    "print(\"Score d'entraitenant : \",model.score(X_train,y_train))\n",
    "print(\"Score de test : \",model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbe de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x140d679d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "k= np.linspace(1,150,10)\n",
    "train_score, val_score = validation_curve(LogisticRegression(),X_train,y_train,param_name='C',param_range=k,cv=5)\n",
    "plt.plot(k,val_score.mean(axis=1),label='validation')\n",
    "plt.plot(k,train_score.mean(axis=1),label='train')\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbe d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/maestro/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/maestro/Documents/Data_science_books/stage_master_ginfo_cloud/modele_prediction/prediction_pathologie_pescriptions.ipynb Cellule 49\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maestro/Documents/Data_science_books/stage_master_ginfo_cloud/modele_prediction/prediction_pathologie_pescriptions.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m N,train_score, val_score \u001b[39m=\u001b[39m learning_curve(model,X_train,y_train,train_sizes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.2\u001b[39m,\u001b[39m1.0\u001b[39m,\u001b[39m10\u001b[39m),cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maestro/Documents/Data_science_books/stage_master_ginfo_cloud/modele_prediction/prediction_pathologie_pescriptions.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(N)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1597\u001b[0m, in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mfor\u001b[39;00m n_train_samples \u001b[39min\u001b[39;00m train_sizes_abs:\n\u001b[1;32m   1595\u001b[0m         train_test_proportions\u001b[39m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[0;32m-> 1597\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m   1598\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m   1599\u001b[0m         clone(estimator),\n\u001b[1;32m   1600\u001b[0m         X,\n\u001b[1;32m   1601\u001b[0m         y,\n\u001b[1;32m   1602\u001b[0m         scorer,\n\u001b[1;32m   1603\u001b[0m         train,\n\u001b[1;32m   1604\u001b[0m         test,\n\u001b[1;32m   1605\u001b[0m         verbose,\n\u001b[1;32m   1606\u001b[0m         parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1607\u001b[0m         fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[1;32m   1608\u001b[0m         return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1609\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m   1610\u001b[0m         return_times\u001b[39m=\u001b[39mreturn_times,\n\u001b[1;32m   1611\u001b[0m     )\n\u001b[1;32m   1612\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m train_test_proportions\n\u001b[1;32m   1613\u001b[0m )\n\u001b[1;32m   1614\u001b[0m results \u001b[39m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[1;32m   1615\u001b[0m train_scores \u001b[39m=\u001b[39m results[\u001b[39m\"\u001b[39m\u001b[39mtrain_scores\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_unique_ticks)\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N,train_score, val_score = learning_curve(model,X_train,y_train,train_sizes = np.linspace(0.2,1.0,10),cv=5)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N,val_score.mean(axis=1),label='learning')\n",
    "plt.plot(N,train_score.mean(axis=1),label='train')\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('score')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
